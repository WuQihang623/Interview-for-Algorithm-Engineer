<h1 style="text-align:center;">面试内容
</h1>
<h2 style="text-align:center;"> 计算机基础知识</h2>

### 如何将RGB图像转成灰度图像

常见的转换方法是将RGB三个通道的值按照一定的权重进行加权平均，得到对应的灰度值。这些权重通常是根据人眼对不同颜色的敏感程度来确定的，例如常用的权重系数是：**灰度值 = 0.2989 * R + 0.5870 * G + 0.1140 * B**

将灰度图转成RGB转换过程中会丢失颜色信息。一种简单的方法是将灰度值作为RGB的三个通道的值。另一种常见的方法是使用伪彩色映射（Pseudocolor mapping），即将灰度图的灰度值映射到一个伪彩色表中，将不同灰度值映射到不同的颜色上。

### 你了解设计模式吗？在python中如何实现单例模式？

- 单例模式（Singleton Pattern）：确保一个类只有一个实例，并提供一个全局访问点。
- 工厂模式（Factory Pattern）：定义一个用于创建对象的接口，但将实际的创建工作推迟到子类中。
- 抽象工厂模式（Abstract Factory Pattern）：提供一个创建一系列相关或相互依赖对象的接口，而无需指定其具体类。
- 建造者模式（Builder Pattern）：将一个复杂对象的构建与其表示分离，使得同样的构建过程可以创建不同的表示。

#### 如何实现单例模式

1. 在定义类前采用修饰器@singleton

2. 使用了类方法 `__new__`，在对象创建之前进行检查，确保只有一个实例被创建，并且保证了线程安全性。

   ```python
   class Singleton:
       _instance = None
   
       def __new__(cls, *args, **kwargs):
           if cls._instance is None:
               cls._instance = super().__new__(cls, *args, **kwargs)
           return cls._instance
   
   class MyClass(Singleton):
       def __init__(self, name):
           self.name = name
   
   # 创建实例
   obj1 = MyClass("instance1")
   obj2 = MyClass("instance2")
   
   print(obj1.name)  # 输出：instance1
   print(obj2.name)  # 输出：instance1（因为它是同一个实例）
   ```

   #### 单例模式的优点：

   1. **全局唯一实例：** 保证一个类只有一个实例，对于频繁使用的对象，可以节省系统资源。
   2. **延迟实例化：** 可以延迟实例的创建，直到需要时再进行初始化。
   3. **避免竞态条件：** 在多线程环境中，单例模式可以避免竞态条件，确保只有一个实例被创建。

   #### 单例模式的缺点：

   1. **全局状态：** 单例模式引入了全局状态，可能导致程序的复杂性增加。
   2. **隐藏依赖：** 单例模式可能隐藏了类之间的依赖关系，使得代码难以理解和维护。

   #### 适用场景：

   1. 当一个系统只需要一个实例来协调行为时。

   2. 当实例需要被频繁访问，而不希望通过参数传递来获取实例。

   3. 当一个类的实例需要被全局访问，并且这个实例负责协调操作。

   #### 如何实现工厂模式

   ```pyth
   class Product:
       def operation(self):
           pass
   
   class ConcreteProduct1(Product):
       def operation(self):
           return "Operation from ConcreteProduct1"
   
   class ConcreteProduct2(Product):
       def operation(self):
           return "Operation from ConcreteProduct2"
   
   class SimpleFactory:
       @staticmethod
       def create_product(product_type):
           if product_type == "product1":
               return ConcreteProduct1()
           elif product_type == "product2":
               return ConcreteProduct2()
           else:
               raise ValueError("Invalid product type")
   
   # 使用工厂创建对象
   factory = SimpleFactory()
   product1 = factory.create_product("product1")
   product2 = factory.create_product("product2")
   
   print(product1.operation())  # 输出：Operation from ConcreteProduct1
   print(product2.operation())  # 输出：Operation from ConcreteProduct2
   
   ```

   #### 工厂模式的优点：

   1. **封装对象创建逻辑：** 工厂模式将对象的创建过程封装在工厂类中，客户端无需了解对象的创建过程，只需通过工厂类获取对象。
   2. **可扩展性：** 新增产品类时，只需要扩展工厂类而不需要修改客户端代码，符合开闭原则。
   3. **解耦：** 将具体产品类和客户端代码解耦，使得系统更易于维护和扩展。

   #### 工厂模式的缺点：

   1. **类数量增多：** 随着产品类的增多，可能导致工厂类的数量也增多，使得代码结构复杂。
   2. **不符合开闭原则的变体：** 在简单工厂模式中，每次新增产品都需要修改工厂类，不符合开闭原则。

   #### 工厂模式适用情景：

   1. 当一个系统需要独立于其创建、组合和表示时。

   2. 当一个系统需要多个产品系列中的一种，并且客户端不关心这些对象的创建细节。

   3. 当一个系统需要动态配置对象。

   

### C++有什么特性？

1. **面向对象编程（Object-Oriented Programming, OOP）**：C++ 支持面向对象编程，包括类、对象、继承、多态等概念，使得代码结构更加模块化和可重用。
2. **泛型编程（Generic Programming）**：C++ 支持泛型编程，通过模板（template）实现通用的算法和数据结构，提高了代码的灵活性和复用性。
3. **多重继承（Multiple Inheritance）**：C++ 允许一个类继承自多个基类，这使得在设计复杂系统时能够更好地表达对象之间的关系。
4. **内存管理**：C++ 具有灵活的内存管理能力，包括手动内存管理（使用 new 和 delete 操作符）和智能指针（如 std::shared_ptr、std::unique_ptr），可以有效地管理内存资源。
5. **运算符重载（Operator Overloading）**：C++ 允许用户重载运算符，使得用户定义的类型可以像内置类型一样使用运算符进行操作。
6. **异常处理（Exception Handling）**：C++ 提供了异常处理机制，通过 try-catch 块捕获和处理异常，使得程序能够更加健壮和可靠。
7. **标准模板库（Standard Template Library, STL）**：STL 是 C++ 标准库的一部分，包含了丰富的通用数据结构和算法，如容器（vector、list、map 等）和算法（排序、查找、遍历等），提高了编程效率和代码质量。
8. **高效的性能**：C++ 是一种高性能的语言，具有接近于底层的控制和优化能力，适用于开发对性能要求较高的系统和应用程序。
9. **平台独立性**：C++ 是一种跨平台的语言，可以在多种操作系统上编译和运行，如 Windows、Linux、macOS 等。
10. **友元函数和友元类（Friend Function and Friend Class）**：C++ 允许将函数或类声明为另一个类的友元，使得这些函数或类能够访问该类的私有成员。
11. **支持低级操作**：C++ 允许直接操作内存，包括指针、引用、位操作等，使得开发者能够更加灵活地进行系统级别的编程。

#### 面向对象编程的特点和核心概念：

1. **类与对象**：
   - 类（Class）是一种用户自定义的数据类型，用于描述一类对象的共同属性和行为。类可以看作是对象的模板或蓝图。
   - 对象（Object）是类的实例，具体化了类的属性和行为。对象是程序中的实体，具有状态、行为和标识。
2. **封装（Encapsulation）**：
   - 封装是指将数据和操作封装在类的内部，隐藏了对象的内部实现细节，只提供公共的接口供外部访问。
   - 封装可以提高代码的安全性和可维护性，减少了对象之间的耦合度。
3. **继承（Inheritance）**：
   - 继承是一种机制，允许一个类（子类）继承另一个类（父类）的属性和方法，并且可以在此基础上进行扩展或修改。
   - 继承可以提高代码的重用性，减少了重复编写代码的工作量。
4. **多态（Polymorphism）**：
   - 多态是指同一个操作作用于不同的对象上时，可以产生不同的行为。
   - 多态通过函数重载、运算符重载和虚函数等机制实现，使得程序更加灵活和可扩展。

面向对象编程的主要目标是提高代码的**重用性、可扩展性和可维护性**，通过封装、继承和多态等特性，使得程序结构更加清晰和易于理解。

#### 标准模板库

STL 主要包含以下三个组件：

1. **容器（Containers）**： 容器是用来存储数据的数据结构，STL 提供了多种类型的容器，包括顺序容器和关联容器。
   - 顺序容器（Sequential Containers）：如 vector、list、deque、array 等，用于按顺序存储和访问元素。
   - 关联容器（Associative Containers）：如 set、map、multiset、multimap 等，用于按键值进行快速查找和访问元素。
2. **算法（Algorithms）**： 算法是对容器中的数据进行操作和处理的函数，STL 提供了一系列的通用算法，如排序、查找、合并、计算等。 这些算法通过迭代器（Iterators）来访问容器中的元素，使得算法与数据结构解耦合，提高了算法的复用性和灵活性。
3. **迭代器（Iterators）**： 迭代器是一种类似于指针的对象，用于在容器中遍历和访问元素，STL 提供了多种类型的迭代器，如输入迭代器、输出迭代器、正向迭代器、随机访问迭代器等。 迭代器提供了统一的接口，使得算法可以在不同类型的容器上进行操作，而无需关心容器的具体实现细节。

#### 虚函数的概念

通过在基类中声明虚函数，派生类可以覆盖（override）基类中的虚函数，从而在运行时确定调用的是哪个版本的函数。这种机制称为动态绑定（dynamic binding）或运行时多态（runtime polymorphism）。

**1. 在基类中声明虚函数：** 在基类中将函数声明为虚函数，使用 `virtual` 关键字进行修饰。这样，派生类可以选择性地覆盖基类中的虚函数。

```C++
class Base {
public:
    virtual void show() {
        cout << "Base class function" << endl;
    }
};
```

**2. 在派生类中覆盖虚函数：** 派生类可以重新定义基类中的虚函数，实现自己特定的行为。派生类中的函数声明必须与基类中的虚函数声明相匹配。

```C++
class Derived : public Base {
public:
    void show() override {
        cout << "Derived class function" << endl;
    }
};
```

3. **动态绑定：** 当基类指针（或引用）指向派生类对象时，通过虚函数的动态绑定机制，在运行时确定调用的是派生类中的版本还是基类中的版本。这样可以根据对象的实际类型来调用对应的函数。

```C++
int main() {
    Base* ptr = new Derived();
    ptr->show(); // 调用的是Derived类中的show函数
    delete ptr;
    return 0;
}
```



### Python与C++的区别

1. **语法和风格：**
   - Python 的语法简洁清晰，采用缩进来表示代码块，没有大括号；而 C++ 的语法更加严格，采用分号和大括号来表示代码块。
   - Python 是一种解释型语言，代码无需编译即可执行；而 C++ 是一种编译型语言，需要先编译成机器码再执行。
2. **类型系统：**
   - Python 是一种动态类型语言，变量的类型在运行时确定，无需显式声明；而 C++ 是一种静态类型语言，变量的类型在编译时确定，需要显式声明。
   - Python 的变量可以指向任意类型的对象；而 C++ 的变量必须指定特定类型，并且类型在编译时是固定的。
3. **内存管理：**
   - Python 使用自动内存管理机制（垃圾回收），通过引用计数和循环垃圾收集来管理内存；而 C++ 需要程序员手动管理内存，包括分配和释放内存。
   - Python 的内存管理机制简化了程序开发，但可能导致性能损失和内存泄漏；而 C++ 的手动内存管理更加灵活，但需要程序员更加小心地处理内存。
4. **面向对象编程：**
   - Python 和 C++ 都支持面向对象编程，但其实现方式有所不同。
   - Python 的面向对象特性更加简单和灵活，支持动态继承、动态绑定等特性；而 C++ 的面向对象特性更加丰富，包括多重继承、虚函数、纯虚函数等。
5. **标准库和生态系统：**
   - Python 拥有丰富的标准库和第三方库，涵盖了几乎所有领域的应用开发，如科学计算、网络编程、Web 开发等；而 C++ 的标准库和第三方库相对较少，需要程序员自己去选择和引入。
6. **适用场景：**
   - Python 适用于快速开发、原型设计、数据分析、科学计算等领域，尤其擅长处理复杂的业务逻辑和高层次的任务。
   - C++ 适用于系统编程、游戏开发、嵌入式系统、性能优化等领域，尤其擅长处理底层的系统级别的任务和对性能要求较高的场景。

### 在项目中使用过多线程吗，是如何实现的？

1. **线程创建：** 程序员可以使用操作系统提供的线程库（如 POSIX 线程库 pthreads）或语言级别的多线程库（如 Java 中的 `Thread` 类）来创建线程。线程创建时需要指定线程函数或线程对象，并传递相应的参数。
2. **线程调度：** 操作系统负责线程的调度和管理，根据线程的优先级、状态和调度策略来决定哪个线程可以获得 CPU 时间片执行任务。常见的调度策略包括先来先服务（FCFS）、最短作业优先（SJF）、轮转调度（Round Robin）等。
3. **线程同步：** 多线程程序中，可能会存在共享资源的竞争和冲突，需要通过同步机制来确保多个线程之间的数据访问安全。常见的线程同步机制包括互斥锁（Mutex）、信号量（Semaphore）、条件变量（Condition Variable）等。
4. **线程通信：** 多线程程序中的线程之间可能需要进行通信和协作，以实现共同的任务目标。线程通信机制可以通过共享内存、消息队列、管道等方式来实现。
5. **线程销毁：** 线程执行完成后，需要及时释放线程所占用的资源，以防止资源泄漏和系统资源浪费。操作系统负责线程的销毁和资源回收。

#### 1. 互斥锁（Mutex）：

**概念：** 互斥锁是一种用于保护临界区的同步机制，用于确保在同一时刻只有一个线程可以访问共享资源。当一个线程进入临界区时，它会尝试获得互斥锁，如果互斥锁已被其他线程占用，则该线程会被阻塞，直到互斥锁被释放。

**特点：**

- 互斥锁是一种二进制锁，只有两种状态：锁定和解锁。
- 只有成功获得互斥锁的线程才能进入临界区，其他线程被阻塞。
- 互斥锁是一种独占锁，只能由获得锁的线程释放。

#### 2. 信号量（Semaphore）：

**概念：** 信号量是一种计数器，用于控制同时访问共享资源的线程数量。当一个线程进入临界区时，它会尝试获取信号量，如果信号量的值大于 0，则表示资源可用，线程可以继续执行；如果信号量的值等于 0，则表示资源不可用，线程会被阻塞，直到资源可用。

**特点：**

- 信号量是一种整数型变量，可以有多种取值。
- 信号量可以用于解决生产者-消费者问题、限流等场景。
- 信号量可以是二进制信号量（取值为 0 或 1）或计数信号量（取值大于等于 0）。

#### 3. 条件变量（Condition Variable）：

**概念：** 条件变量是一种线程间的通信机制，用于在多线程环境中实现线程的等待和唤醒操作。条件变量通常与互斥锁配合使用，等待线程在条件不满足时会阻塞，并释放互斥锁；当条件满足时，唤醒线程并重新获取互斥锁，继续执行。

**特点：**

- 条件变量用于解决线程间的同步和通信问题，允许线程在特定条件下等待或唤醒。
- 条件变量通常与互斥锁一起使用，互斥锁用于保护条件变量的访问和修改。



### TCP与UDP有什么区别，各有什么优劣？

TCP（传输控制协议）和UDP（用户数据报协议）是两种不同的传输层协议，用于在计算机网络中传输数据。它们之间的主要差异包括：

1. **连接性**：
   - TCP 是面向连接的协议，它在通信之前需要建立连接，然后在通信结束时释放连接。这种连接方式保证了数据的可靠性和顺序性。
   - UDP 是无连接的协议，通信双方在发送数据之前不需要建立连接，也不需要维护连接状态。因此，UDP 的通信速度通常比 TCP 快，但不具备 TCP 那种可靠性和顺序性。
2. **可靠性**：
   - TCP 提供可靠的数据传输。它通过序号、确认和重传机制来确保数据的可靠性，即使在网络出现丢包或者出现延迟的情况下，也能够保证数据的完整性和顺序性。
   - UDP 不提供可靠的数据传输保证。它仅仅提供了数据的最基本的传输功能，不对数据进行确认和重传，因此在网络不可靠或者对实时性要求较高的情况下使用。
3. **头部开销**：
   - TCP 的头部开销相对较大，因为它需要包含序号、确认号、窗口大小等控制信息，以及可选的选项字段。
   - UDP 的头部开销较小，只包含了源端口、目标端口、长度和校验和等基本信息，因此 UDP 的头部开销比 TCP 小。
4. **适用场景**：
   - TCP 适用于对数据传输可靠性要求较高的场景，如文件传输、网页浏览、电子邮件等。
   - UDP 适用于实时性要求较高，且对数据可靠性要求不高的场景，如音视频流媒体、在线游戏等。

**TCP优点：**

- 可靠性高，适用于对数据传输可靠性要求较高的场景，如文件传输、网页浏览等。

**TCP缺点：**

- 建立连接和断开连接的开销较大，影响了数据传输的实时性。
- 数据传输的实时性较差，不适用于对实时性要求较高的场景，如实时视频传输、游戏等。

**UDP优点：**

- 建立连接和断开连接的开销小，适用于对数据传输实时性要求较高的场景，如实时音频传输、视频会议等。
- 数据传输的实时性好，不受连接建立和断开的影响。

**UDP缺点：**

- 不可靠性高，数据传输可能会丢失或乱序，需要应用层进行数据重传和确认。
- 不提供流量控制机制，容易导致网络拥塞，影响数据传输的稳定性。

#### TCP为什么要经历三次握手

1. **确认双方能够正常收发数据：** 第一次握手中，客户端向服务器发送连接请求报文段，服务器收到后进行确认，并进入 SYN-RCVD 状态；第二次握手中，服务器向客户端发送连接确认报文段，客户端收到后也进入 ESTABLISHED 状态；第三次握手中，客户端向服务器发送确认报文段，服务器收到后也进入 ESTABLISHED 状态。通过这个过程，确保了双方都能够正常收发数据。
2. **防止已失效的连接请求报文段被服务端误认为是新的连接请求：** 如果只进行两次握手，那么在某些情况下，客户端发送的连接请求报文段可能会在网络中被延迟，导致服务端收到后进行确认，但客户端并未收到确认，此时客户端会认为连接未建立成功，并重新发送连接请求。而服务端可能会收到之前已经确认过的连接请求报文段，并错误地认为是新的连接请求。因此，通过第三次握手，可以避免这种情况发生，确保已失效的连接请求报文段不会被误认为是新的连接请求。
3. **确保连接的可靠性：** 三次握手过程中，客户端和服务端都有机会确认对方的身份和能力，并且在第三次握手中，客户端和服务端都对连接进行了确认，从而确保了连接的可靠性和稳定性。



### TCP的四次挥手过程

终止一个已建立的 TCP 连接。这个过程涉及到两端（客户端和服务器端）互相发送控制信息以关闭连接。

1. 第一次挥手：客户端向服务器端发送一个 TCP 报文段，设置 FIN 标志位，表示客户端已经没有数据要发送了，但仍然可以接收数据。客户端进入 FIN_WAIT_1 状态，等待服务器端的确认。
2. 第二次挥手：服务器端收到客户端发送的 FIN 报文段后，会发送一个 ACK 报文段作为确认。此时服务器端进入 CLOSE_WAIT 状态，表示已经收到了客户端的关闭请求，但服务器端还有数据需要发送给客户端。
3. 第三次挥手：当服务器端确定数据都发送完毕后，会向客户端发送一个 FIN 报文段，表示服务器端已经没有数据要发送了。服务器端进入 LAST_ACK 状态。
4. 第四次挥手：客户端收到服务器端发送的 FIN 报文段后，客户端会发送一个 ACK 报文段作为确认。客户端进入 TIME_WAIT 状态，等待可能出现的延迟报文。



### 介绍虚继承

虚继承的主要作用是解决由多重继承导致的菱形继承（Diamond Inheritance）问题。在多重继承中，如果一个类同时继承自两个或多个具有共同基类的类，而这些共同基类又有一个共同的派生类，就会形成菱形继承的结构。这样的继承结构可能会导致问题，例如数据成员在派生类中出现多次，导致冗余或不一致性。**虚继承通过在派生类对共同基类进行虚继承来解决这个问题。使用虚继承后，共同基类在继承体系中只会被派生类保留一份**

```C++
class Base {
public:
    int data;
};

class Derived1 : virtual public Base {
    // Derived1 可以通过 Base 继承的 data
};

class Derived2 : virtual public Base {
    // Derived2 可以通过 Base 继承的 data
};

class FinalDerived : public Derived1, public Derived2 {
    // 可以直接访问 Base 继承的 data，而不会有二义性
};
```

### C++的结构体内存对齐

尽管内存是以字节为单位，但是大部分处理器并不是按字节块来存取内存的.它一般会以双字节,四字节,8字节,16字节甚至32字节为单位来存取内存，我们将上述这些存取单位称为内存存取粒度。32位系统处理器只能从地址为4的倍数的内存开始读取数据。内存对齐的目的是为了提高内存访问的效率，减少内存访问的次数，以及避免因为非对齐内存访问而引起的性能损失。

C++ 中结构体的内存对齐规则如下：

1. 结构体的每个成员变量的起始地址必须是其自身大小的整数倍。
2. 结构体的大小必须是其最大成员大小的整数倍。

### Linux常用命令

`ls`: 列出当前目录的内容。

`ls -l`: 以长格式列出当前目录的内容，包括文件权限、所有者、大小等信息。

`ls -a`: 列出当前目录的所有内容，包括隐藏文件。

`pwd`: 显示当前工作目录的完整路径。

`rm -f`: 强制删除，不提示确认。

`rm -r`: 递归删除目录及其内容。

`rmdir`: 删除一个空目录。

`cp -r`: 递归复制目录及其内容。

`cat`: 查看文件内容。

`more` 或 `less`: 分页查看文件内容，可以滚动查看大文件。

`nano` 或 `vi` 或 `vim`: 编辑文件的内容。

`chmod`: 改变文件或目录的权限。

```Ba
-R：递归地修改目录及其下属文件和子目录的权限。
符号：+ 表示添加权限，- 表示删除权限，= 表示设置权限。
权限：r 表示读权限，w 表示写权限，x 表示执行权限。
用户类型：u 表示所有者，g 表示所属组，o 表示其他用户，a 表示所有用户。
chmod u+x file.txt：给文件的所有者添加执行权限。
chmod a=rwx directory：设置目录的所有用户都具有读、写、执行权限。
```

`find`: 在指定目录中搜索文件。

```bash
find 路径 [选项] [表达式]
-name 模式：按照文件名模式进行搜索，模式可以使用通配符。
-type 类型：指定要搜索的文件类型，如 f 表示普通文件，d 表示目录。
-size 大小：按照文件大小进行搜索，可以使用 + 表示大于，- 表示小于，以及 c 表示字节、k 表示千字节、M 表示兆字节等单位。
-mtime +n/-n：按照修改时间进行搜索，+n 表示修改时间在 n 天之前，-n 表示修改时间在 n 天之内。
find /path/to/search -type d -mtime -7 -exec ls -ld {} \;：搜索指定目录下最近 7 天内修改过的目录，并输出详细信息。
```

### 深度优先遍历和广度优先遍历

### 广度优先搜索（BFS）：

- **原理**：BFS从图中的某个起始节点开始，首先遍历起始节点的所有邻居节点，然后再依次遍历邻居节点的邻居节点，以此类推，直到遍历完整个图为止。它按层级的顺序逐层遍历，先访问距离起始节点最近的节点。
- **数据结构**：通常使用队列（Queue）来实现BFS，起始节点入队，然后出队时将其邻居节点入队，依次进行。
- **应用**：BFS常用于寻找最短路径、查找图的连通性、生成迷宫等。

### 深度优先搜索（DFS）：

- **原理**：DFS从图中的某个起始节点开始，首先遍历起始节点的一个邻居节点，然后再以同样的方式遍历该邻居节点的一个邻居节点，依次进行直到到达最深的节点，然后再回溯到前面的节点，以同样的方式遍历其他未被访问过的邻居节点，直到所有节点都被访问过。
- **数据结构**：通常使用递归或者栈（Stack）来实现DFS。递归方式下，函数自己调用自己，栈方式下，手动维护一个栈来保存节点。
- **应用**：DFS常用于图的遍历、拓扑排序、寻找连通分量、解决迷宫问题等。

### 区别：

1. **访问顺序**：BFS按层级顺序遍历，先访问离起始节点最近的节点；DFS先遍历当前节点的一个分支，直到末端再回溯到前面的节点继续搜索其他分支。
2. **数据结构**：BFS通常使用队列，而DFS通常使用递归或者栈。
3. **空间复杂度**：BFS在存储未访问节点时需要较大的空间，因为它需要将所有的当前层节点都存储起来，而DFS则不需要这样做，因此在空间上DFS比BFS更节省。
4. **时间复杂度**：在相同的条件下，BFS和DFS的时间复杂度一样，都是 O*(*V*+*E)，其中V是节点数，E 是边数。
5. **应用场景**：具体应用场景不同。BFS适用于解决最短路径等问题，而DFS适用于拓扑排序、连通分量等问题。



<h1 style="text-align:center;">手撕算法
</h1>

### 背包问题总结

#### 背包递推公式：

1. 问是否能装满背包，或者最多能装多少：

```C++
dp[j]=max(dp[j], dp[j-nums[i]]+nums[i]);
```

2. 问装满背包有几种方法：

```C++
dp[0] = 1;
dp[j] += dp[j-nums[i]];
```

3. 问装满背包所有物品的最小个数：

```C++
vector<int> dp(size+1, INT_MAX);
dp[0] = 0;
dp[j] = min(dp[j-coins[i]]+1, dp[j]);
```

#### 遍历顺序

1. 01背包，物品只有一个，选或者不选

先遍历物品再遍历背包，且第二层for是从大到小遍历

2. 完全背包，物品有无数个，不选或者选几个

完全背包第二层for循环从小到大遍历

**求组合数：**外层for遍历物品，内层for遍历背包

**求排列数：**外层for遍历背包，内层for遍历物品

**求最小数：**两层for循环的先后顺序无所谓



### 链表反转



### 如何寻找二次曲线的最小值

```py
# y=a*x^2+b*x+c
def gradient(x, a, b):
    return 2*a*x+b
def gradient_descent(lr, iterations, x, a, b):
    for _ in range(iterations):
        grad = gradient(x, a, b)
        x -= lr*grad
    return x
```



### 用两个栈实现队列



### 判断链表中是否有环



### 合并两个有序数组



### 链表中的节点每k个组翻转



### 超级丑数



### 查找和最小的k对数字



### 有序矩阵中的第k个最小数组和









<h1 style="text-align:center;">AI算法题
</h1>

### 常见的注意力机制

1. SE模块

```python
class SELayer(nn.Module):
    def __init__(self, channel, reduction=16):
        super(SELayer, self).__init__()
        self.avg_pool = nn.AdaptiveAvgPool2d(1)
        self.fc = nn.Sequential(
            nn.Linear(channel, channel // reduction, bias=False),
            nn.ReLU(inplace=True),
            nn.Linear(channel // reduction, channel, bias=False),
            nn.Sigmoid()
        )
 
    def forward(self, x):
        b, c, _, _ = x.size()
        y = self.avg_pool(x).view(b, c)
        y = self.fc(y).view(b, c, 1, 1)
        return x * y.expand_as(x)
```



![img](https://img-blog.csdnimg.cn/e68deb8b324841d09aaced4ce9cd3a8e.png)

2. CA模块

```python
import torch
from torch import nn
class CA_Block(nn.Module):
    def __init__(self, channel, h, w, reduction=16):
        super(CA_Block, self).__init__()
        self.h = h
        self.w = w
        self.avg_pool_x = nn.AdaptiveAvgPool2d((h, 1))
        self.avg_pool_y = nn.AdaptiveAvgPool2d((1, w))
        self.conv_1x1 = nn.Conv2d(in_channels=channel, out_channels=channel//reduction, kernel_size=1, stride=1, bias=False)
        self.relu = nn.ReLU()
        self.bn = nn.BatchNorm2d(channel//reduction)
        self.F_h = nn.Conv2d(in_channels=channel//reduction, out_channels=channel, kernel_size=1, stride=1, bias=False)
        self.F_w = nn.Conv2d(in_channels=channel//reduction, out_channels=channel, kernel_size=1, stride=1, bias=False)
        self.sigmoid_h = nn.Sigmoid()
        self.sigmoid_w = nn.Sigmoid()
    def forward(self, x):
        x_h = self.avg_pool_x(x).permute(0, 1, 3, 2)
        x_w = self.avg_pool_y(x)
        x_cat_conv_relu = self.relu(self.conv_1x1(torch.cat((x_h, x_w), 3)))
        x_cat_conv_split_h, x_cat_conv_split_w = x_cat_conv_relu.split([self.h, self.w], 3)
        s_h = self.sigmoid_h(self.F_h(x_cat_conv_split_h.permute(0, 1, 3, 2)))
        s_w = self.sigmoid_w(self.F_w(x_cat_conv_split_w))
        out = x * s_h.expand_as(x) * s_w.expand_as(x)
        return out
```

![img](https://img-blog.csdnimg.cn/232b3dc1ed854fcfb97607d2f71ad7cd.png)

3. 自注意力机制：用于处理序列数据，如文本、语音等。它能够根据序列中各个元素之间的相互关系动态地计算每个元素的权重。

```python
import torch
import torch.nn as nn
import torch.nn.functional as F

class MultiHeadAttention(nn.Module):
    def __init__(self, embed_dim, num_heads):
        super(MultiHeadAttention, self).__init__()
        assert embed_dim % num_heads == 0, "Embedding dimension must be divisible by the number of heads."
        self.embed_dim = embed_dim
        self.num_heads = num_heads
        self.head_dim = embed_dim // num_heads

        # 初始化线性变换矩阵
        self.W_q = nn.Linear(embed_dim, embed_dim, bias=False)
        self.W_k = nn.Linear(embed_dim, embed_dim, bias=False)
        self.W_v = nn.Linear(embed_dim, embed_dim, bias=False)

        # 输出线性变换矩阵
        self.W_o = nn.Linear(embed_dim, embed_dim)

    def forward(self, query, key, value, mask=None):
        batch_size = query.shape[0]

        # 线性变换
        Q = self.W_q(query)  # 形状: (batch_size, seq_len, embed_dim)
        K = self.W_k(key)    # 形状: (batch_size, seq_len, embed_dim)
        V = self.W_v(value)  # 形状: (batch_size, seq_len, embed_dim)

        # 重塑为多头
        Q = Q.view(batch_size, -1, self.num_heads, self.head_dim).permute(0, 2, 1, 3)  # 形状: (batch_size, num_heads, seq_len, head_dim)
        K = K.view(batch_size, -1, self.num_heads, self.head_dim).permute(0, 2, 1, 3)  # 形状: (batch_size, num_heads, seq_len, head_dim)
        V = V.view(batch_size, -1, self.num_heads, self.head_dim).permute(0, 2, 1, 3)  # 形状: (batch_size, num_heads, seq_len, head_dim)

        # 计算注意力分数
        scores = torch.matmul(Q, K.transpose(-2, -1)) / torch.sqrt(torch.tensor(self.head_dim, dtype=torch.float32))
        if mask is not None:
            scores.masked_fill_(mask == 0, float('-inf'))

        # 使用 softmax 激活函数计算注意力权重
        attn_probs = F.softmax(scores, dim=-1)  # 形状: (batch_size, num_heads, seq_len, seq_len)

        # 使用注意力权重对值进行加权求和
        attn_output = torch.matmul(attn_probs, V)  # 形状: (batch_size, num_heads, seq_len, head_dim)

        # 拼接多头并投影回原始嵌入维度
        attn_output = attn_output.permute(0, 2, 1, 3).contiguous().view(batch_size, -1, self.embed_dim)  # 形状: (batch_size, seq_len, embed_dim)

        # 使用线性变换得到最终的注意力输出
        attn_output = self.W_o(attn_output)  # 形状: (batch_size, seq_len, embed_dim)

        return attn_output
```



3. 交叉注意力机制：用于处理具有不同输入的模型，如图像与文本之间的关系。它允许模型在处理不同输入时动态地计算各个输入之间的关联性，从而更好地整合不同输入的信息。

### TensorRT优化流程

1. **网络定义和训练：** 首先，你需要定义一个深度学习模型并进行训练，通常使用常见的深度学习框架如TensorFlow、PyTorch或Caffe等。这个模型可以是用于分类、目标检测、语义分割等各种任务的模型。
2. **模型转换：** 接下来，你需要将训练好的模型转换为TensorRT的可优化格式。TensorRT支持从常见的深度学习框架（如TensorFlow、PyTorch等）导入模型，并将其转换为TensorRT的网络结构格式。这个过程通常被称为模型优化。
3. **网络优化：** 一旦模型被转换为TensorRT的格式，TensorRT可以对网络进行各种优化，以提高推理性能。这些优化包括结构优化、精度混合、内存优化、层融合、图剪枝等。
4. **引擎构建：** 在网络优化完成后，你需要使用TensorRT API构建推理引擎。推理引擎是TensorRT中的一个重要概念，它是一个针对特定硬件配置和推理需求进行了优化的二进制文件。构建引擎的过程会将优化后的网络结构映射到特定的硬件上，以实现最佳的推理性能。
5. **推理过程：** 最后，你可以使用TensorRT推理引擎对输入数据进行推理。推理引擎会利用之前优化的网络结构和硬件特性，高效地执行推理操作，并生成模型对输入数据的预测结果。

### 介绍YOLO v3~YOLO v8



### 为什么UNet在医学图像上表现这么好

1. 医学图像语义较为简单、结构较为固定。所以高级语义信息和低级特征都显得很重要(UNet的skip connection和[U型结构](https://www.zhihu.com/search?q=U型结构&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra={"sourceType"%3A"answer"%2C"sourceId"%3A586501606})就派上了用场)。
2. .数据量少。医学影像的数据获取相对难一些，很多比赛只提供不到100例数据。所以我们设计的模型不宜多大，参数过多，很容易导致[过拟合](https://www.zhihu.com/search?q=过拟合&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra={"sourceType"%3A"answer"%2C"sourceId"%3A586501606})。

### 训练网络时怎么判断有没有过拟合，欠拟合

#### 过拟合：

1. **训练集和验证集损失对比**：监控训练集和验证集的损失。如果训练集的损失持续下降，而验证集的损失却开始上升，则可能出现了过拟合。
2. **训练集和验证集性能对比**：除了损失外，还可以比较训练集和验证集的性能指标，如准确率、精确率、召回率等。如果训练集的性能指标较高，而验证集的性能指标较低，则可能存在过拟合。
3. **可视化训练过程**：可视化训练过程中的损失和性能曲线，观察它们的趋势变化。如果训练集和验证集的曲线出现了分歧，可能出现了过拟合。

#### 欠拟合：

1. **监控训练集和验证集的损失**：如果训练集和验证集的损失都很高，说明模型可能存在欠拟合。这意味着模型无法捕捉数据中的足够信息。
2. **观察模型性能**：监控模型在训练集和验证集上的性能指标。如果性能指标较低，可能是因为模型过于简单，无法很好地拟合数据。
3. **增加模型容量**：如果发现模型出现了欠拟合，可以尝试增加模型的容量，例如增加网络的层数、神经元数量等。
4. **尝试其他模型**：如果增加模型容量仍然无法解决欠拟合问题，可以尝试使用其他更复杂的模型，或者调整模型的架构以更好地适应数据。

### 密集行人检测的遮挡问题怎么解决

1. 损失函数Repulsion loss：
   $$
   L_{Rep}=L_{Attr}+\alpha*L_{RepGT}+\beta*L_{RepBox}
   $$
   其中 $$L_{Attr} $$ 是吸引项，需要预测框靠近其指定目标；$L_RepGT$ 和 $L_RepBox$ 是排斥项，分别需要预测框远离周遭其他的 groundtruth 物体和其他指定目标不同的预测框。



### 自动驾驶检测模型如何针对corner case优化



### 常见的损失函数



### 神经网络优化器有哪些



### GBDT和Adaboost的区别



### 神经网络的初始化方法

1. **零初始化（Zero Initialization）：** 将所有权重参数和偏置参数初始化为零。这种方法简单易行，但可能会导致网络对称性问题，并且不适用于深层网络。

2. **随机初始化（Random Initialization）：** 将权重参数和偏置参数初始化为随机的小值，通常服从某种均匀分布或高斯分布。常见的方法包括使用均匀分布 $[-\epsilon, \epsilon]$ 或者高斯分布 $N(0, \sigma^2)$，其中 $\epsilon$ 和 $\sigma$ 是根据网络结构和层数进行调整的超参数。

3. **Xavier初始化（Xavier Initialization）：** 也称为Glorot初始化，它根据每一层的输入和输出神经元数量来自适应地初始化权重参数。通常，Xavier初始化使用均匀分布，其方差计算如下：

   - 对于sigmoid激活函数：$Var(W) = \frac{2}{n_{in} + n_{out}}$
   - 对于tanh激活函数：$Var(W) = \frac{1}{n_{in} + n_{out}}$
   - 对于ReLU激活函数：$Var(W) = \frac{2}{n_{in}}$

   其中 $n_{in}$ 和 $n_{out}$ 分别是当前层的输入和输出神经元数量。

4. **He初始化（He Initialization）：** 与Xavier初始化类似，但是适用于ReLU激活函数。He初始化使用均匀分布，其方差计算如下：

   - 对于ReLU激活函数：$Var(W) = \frac{2}{n_{in}}$

   其中 $n_{in}$ 是当前层的输入神经元数量。

5. **自适应梯度缩放（Adaptive Gradient Scaling）：** 有些初始化方法结合了梯度缩放来自适应地调整权重初始化。这样的方法可以在训练的早期阶段提供更好的梯度流动，例如Layer-wise Adaptive Rate Scaling (LARS)。

6. **正交初始化（Orthogonal Initialization）：** 使用正交矩阵来初始化权重参数，以确保权重矩阵的正交性。这种方法有助于减少梯度消失和爆炸的问题，并且可以更好地保持梯度的传播性质。

7. **预训练初始化（Pretrained Initialization）：** 在使用预训练模型进行微调时，可以使用已经训练好的模型的参数进行初始化，这种方法在迁移学习中非常常见。



### DETR中匈牙利匹配算法的具体流程



### 为什么Transformer要使用LayerNorm



### 为什么self-attention可以堆叠多层，有什么作用



### 介绍KMeans



### 介绍NMS及其变体



### 多卡的BN如何实现同步

1. **跨GPU批量归一化（Cross-GPU Batch Normalization）：** 在这种方法中，每个GPU都有自己的批量归一化层。在每个mini-batch的处理过程中，每个GPU分别计算出均值和方差，并进行归一化处理。然后，通过在所有GPU上汇总并取平均，来计算整个mini-batch的全局均值和方差。最后，所有GPU上的数据都使用这些全局均值和方差进行归一化。这种方法在训练时可以实现较好的批量归一化效果，但需要在推理时仔细处理，因为此时可能不再有多个GPU可用。
2. **同步批量归一化（Synchronized Batch Normalization）：** 这种方法在训练时和推理时都可以有效地实现批量归一化。在同步批量归一化中，所有GPU上的数据都收集到一个单一的批量上。然后，通过在所有GPU上计算均值和方差，并进行同步操作来得到全局均值和方差。最后，所有GPU上的数据都使用这些全局均值和方差进行归一化。这种方法保证了所有GPU上的数据都使用相同的均值和方差进行归一化，从而确保了批量归一化的一致性。



### 如何检测到未知目标



### 图像边缘检测算子有哪些？





### 各回归损失的计算及其优缺点



### Transformer与CNN的优缺点



### 介绍SVM和逻辑回归



### Canny算子的流程



### NMS的缺点及其改进工作



### 怎么判断联通域是否相邻



### 手写卷积

```python
# 滑动窗口
import numpy as np

def conv2d(image, kernel, padding=(0, 0), stride=(1, 1)):
    # 图像大小
    H, W, C = image.shape
    # 卷积核大小
    K_h, K_w, C = kernel.shape
    # 填充大小
    pad_h, pad_w = padding
    # 步长
    stride_h, stride_w = stride

    # 计算输出图像大小
    out_h = (H + 2 * pad_h - K_h) // stride_h + 1
    out_w = (W + 2 * pad_w - K_w) // stride_w + 1

    # 填充输入图像
    padded_image = np.pad(image, ((pad_h, pad_h), (pad_w, pad_w), (0, 0)), mode='constant')

    # 初始化输出图像
    output = np.zeros((out_h, out_w))

    # 进行卷积运算
    for y in range(0, out_h):
        for x in range(0, out_w):
            # 定义卷积区域
            region = padded_image[y * stride_h:y * stride_h + K_h, x * stride_w:x * stride_w + K_w, :]
            # 计算卷积结果
            output[y, x] = np.sum(region * kernel)

    return output
```



### 介绍SAM模型



### YOLO v8和YOLO v5的区别



### negative prompt怎么做的



### Stable Diffusion的结构和原理



### 大语言模型的微调方法

