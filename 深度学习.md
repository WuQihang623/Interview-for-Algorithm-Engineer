### 敏感度和特异度

在医学诊断、生物统计学和机器学习领域中，敏感性（Sensitivity）和特异性（Specificity）是用来评价诊断测试性能的重要指标。它们的计算公式如下：

1. **敏感性（Sensitivity）**，也称为真阳性率（True Positive Rate, TPR）：
   $$
   Sensitivity(SE)=\frac{TP}{TP+FN}
   $$

2. **特异性（Specificity）**，也称为真阴性率（True Negative Rate, TNR）：
   $$
   Specificity(SP)=\frac{TN}{TN+FP}
   $$

其中：

- TP 是真正例（True Positive），指的是测试结果为阳性且实际上确实为阳性的样本数。
- FN 是假阴例（False Negative），指的是测试结果为阴性但实际上是阳性的样本数。
- TN 是真阴例（True Negative），指的是测试结果为阴性且实际上确实为阴性的样本数。
- FP 是假阳例（False Positive），指的是测试结果为阳性但实际上是阴性的样本数。



### PR曲线

PR曲线（Precision-Recall Curve）是一种用于评估二分类模型性能的可视化工具，特别适用于数据集不平衡或者对正例检测特别关注的情况。在信息检索、计算机视觉和自然语言处理等领域广泛应用。

PR曲线的构建基于以下两个关键指标：

1. **精确率（Precision）**，也称为查准率，是指模型预测为正例的样本中真正为正例的比例：
   $$
   Precision = \frac{\text{True Positives (TP)}}{\text{True Positives (TP)} + \text{False Positives (FP)}}
   $$

2. **召回率（Recall）**，也称为查全率或真正例率（True Positive Rate, TPR），是指模型识别出的所有正例占实际正例总数的比例：

$$
Recall = \frac{\text{True Positives (TP)}}{\text{True Positives (TP)} + \text{False Negatives (FN)}}
$$

为了绘制PR曲线，首先需要根据模型输出的概率或决策阈值的不同设定，计算一系列不同阈值下的精确率和召回率对。然后，以召回率为横坐标，精确率为纵坐标，连接这些点形成一条曲线。这条曲线反映了随着模型对正例判定越来越宽松（提高召回率），精确率是如何变化的。

此外，PR曲线下的面积（Area Under the PR Curve, AUPRC或AP）是一个常用的综合评价指标，它反映了模型整体的性能，AUPRC值越大，说明模型在各个召回率水平上的精确率表现越好，理想的模型应具有AUPRC接近1的表现。



### 神经网络优化器有哪些

1. **随机梯度下降 (SGD)：** 是最基本的优化算法之一，每次迭代随机选择一批样本进行梯度计算和参数更新。虽然简单，但在实践中可能会受到局部极小值、学习率调整等问题的影响。
2. **动量优化器（Momentum）：** 通过引入动量项来加速收敛过程，可以在参数更新时考虑历史梯度的加权和。常见的动量优化器包括标准动量（SGD with Momentum）、Nesterov 动量等。
3. **AdaGrad：** 自适应学习率的方法之一，通过对每个参数的学习率进行适应性调整，使得稀疏梯度对应的学习率较大，而频繁出现的梯度对应的学习率较小。
4. **RMSProp：** 根据梯度的历史信息来调整学习率，对 AdaGrad 进行了改进，通过指数加权移动平均的方式对历史梯度进行衰减。
5. **Adam：** 结合了动量优化器和 RMSProp 的优点，在计算动量和学习率时考虑了梯度的一阶矩估计（均值）和二阶矩估计（方差），并使用偏差修正来提高稳定性。



### 训练网络时怎么判断有没有过拟合，欠拟合

#### 过拟合：

1. **训练集和验证集损失对比**：监控训练集和验证集的损失。如果训练集的损失持续下降，而验证集的损失却开始上升，则可能出现了过拟合。
2. **训练集和验证集性能对比**：除了损失外，还可以比较训练集和验证集的性能指标，如准确率、精确率、召回率等。如果训练集的性能指标较高，而验证集的性能指标较低，则可能存在过拟合。
3. **可视化训练过程**：可视化训练过程中的损失和性能曲线，观察它们的趋势变化。如果训练集和验证集的曲线出现了分歧，可能出现了过拟合。

#### 欠拟合：

1. **监控训练集和验证集的损失**：如果训练集和验证集的损失都很高，说明模型可能存在欠拟合。这意味着模型无法捕捉数据中的足够信息。
2. **观察模型性能**：监控模型在训练集和验证集上的性能指标。如果性能指标较低，可能是因为模型过于简单，无法很好地拟合数据。
3. **增加模型容量**：如果发现模型出现了欠拟合，可以尝试增加模型的容量，例如增加网络的层数、神经元数量等。
4. **尝试其他模型**：如果增加模型容量仍然无法解决欠拟合问题，可以尝试使用其他更复杂的模型，或者调整模型的架构以更好地适应数据。



### 常见的损失函数

1. 均方误差：适用于回归任务，用于衡量预测值与真实值之间的平均差异。

   优点：在训练过程中，优化过程较为简单，且可微分，有利于梯度下降。

   缺点：对异常值敏感，可能导致模型过度关注异常值。

2. 交叉熵损失：交叉熵损失在分类任务中表现良好，它将概率分布的差异转化为损失值，使得模型更加关注于正确类别的预测。

   优点：对于分类任务，尤其是二分类或多分类任务，交叉熵损失通常是首选的损失函数。

   缺点：不适用于回归任务，而且可能出现梯度消失问题。

3. 平均绝对误差：MAE 对异常值相对较为鲁棒，因为它是误差的绝对值的平均值。

   优点：MAE 对异常值不那么敏感，能够更好地反映数据的实际分布情况。

   缺点：不易优化，因为它在零点附近不是光滑可微的。

4. Hinge损失：Hinge损失适用于支持向量机等分类器，对于大间隔分类有较好的性能。

   优点：对于分类任务，能够产生稀疏的解，适用于处理大规模数据。

   缺点：不适用于概率输出的模型，不能直接用于多类别分类问题。

5. Dice损失：主要用于图像分割任务，能够衡量预测分割与真实分割之间的重叠程度。

   优点：适用于处理像素级别的分割任务，尤其在医学图像分割领域有较好的表现。

   缺点：可能无法直接推广到其他类型的任务。



### 讲一讲常见的激活函数和优缺点

1. **Sigmoid 函数**：$\sigma(x)=\frac{1}{1+e^{-x}}$​

   优点：1.输出范围在 (0, 1) 之间，可以用于二分类问题的输出；2. 具有良好的导数性质，易于求导。

   缺点：1. Sigmoid 函数的梯度在接近饱和区域时会变得很小，导致梯度消失问题；2 . 执行指数运算，计算机运行得较慢。3. 函数输出不是以 0 为中心的，这会降低权重更新的效率；

2. ReLU函数： $f(x)=max(0, x)$

   优点：1. 计算简单，只需比较输入是否大于零。2. 在正数区间上不存在梯度消失问题，能够加速模型的收敛。

   缺点：1. 在负数区间上输出为零，可能导致神经元死亡; 2. 函数输出不是以 0 为中心的，这会降低权重更新的效率；

3. Tanh函数：$f{x}=\frac{2}{1+e^{-2x}}-1$

​	优点：1. 输出以零为中心，有助于缓解梯度消失问题。2. 输出以零为中心

​	缺点：1. 仍然存在梯度消失问题，特别是在接近饱和区域时。

4. Softmax函数: $f(x)=\frac{e^{x_i}}{\sum_{i=1}^ne^{x_j}}$

​	优点： 适用于多类别分类问题，可以将网络输出转换为概率分布。

​	缺点： 求解过程中可能会受到数值稳定性的影响，特别是当输入较大或较小时。



### 神经网络的初始化方法

1. **零初始化（Zero Initialization）：** 将所有权重参数和偏置参数初始化为零。这种方法简单易行，但可能会导致网络对称性问题，并且不适用于深层网络。

2. **随机初始化（Random Initialization）：** 将权重参数和偏置参数初始化为随机的小值，通常服从某种均匀分布或高斯分布。常见的方法包括使用均匀分布 $[-\epsilon, \epsilon]$ 或者高斯分布 $N(0, \sigma^2)$，其中 $\epsilon$ 和 $\sigma$ 是根据网络结构和层数进行调整的超参数。

3. **Xavier初始化（Xavier Initialization）：** 也称为Glorot初始化，它根据每一层的输入和输出神经元数量来自适应地初始化权重参数。通常，Xavier初始化使用均匀分布，其方差计算如下：

   - 对于sigmoid激活函数：$Var(W) = \frac{2}{n_{in} + n_{out}}$
   - 对于tanh激活函数：$Var(W) = \frac{1}{n_{in} + n_{out}}$
   - 对于ReLU激活函数：$Var(W) = \frac{2}{n_{in}}$

   其中 $n_{in}$ 和 $n_{out}$ 分别是当前层的输入和输出神经元数量。

4. **He初始化（He Initialization）：** 与Xavier初始化类似，但是适用于ReLU激活函数。He初始化使用均匀分布，其方差计算如下：

   - 对于ReLU激活函数：$Var(W) = \frac{2}{n_{in}}$

   其中 $n_{in}$ 是当前层的输入神经元数量。

5. **预训练初始化（Pretrained Initialization）：** 在使用预训练模型进行微调时，可以使用已经训练好的模型的参数进行初始化，这种方法在迁移学习中非常常见。



### 正则化为什么可以增加模型泛化能力

**只要一个模型足够复杂，它可以记住所有的训练集合样本之间的映射，代价就是模型复杂，带来的副作用就是没见过的只是略有不同的样本可能表现地就很差**。造成这种情况的问题就是学的太过，参数拟合的太好以致于超过了前面那个训练曲线的最低泛化误差临界点，究其根本原因是模型的表达能力足够强大到过拟合数据集。



### 分类任务目标函数

1. **交叉熵损失（Cross-Entropy Loss）**：

   - 交叉熵是一种用于衡量两个概率分布之间差异的指标。在分类任务中，交叉熵损失用于衡量模型对于每个类别的预测概率与真实标签之间的差异。
   - 交叉熵损失函数通常用于多分类任务，例如 softmax 分类器的输出与真实标签之间的交叉熵损失。
   - 公式：$L=-\sum_{i=1}^Ny_ilog(\hat y_i)$

2. **Hinge Loss**：

   - Hinge Loss 主要用于支持向量机（SVM）等模型的训练，通常用于二分类任务。它衡量了模型对于正确类别的预测分数是否大于错误类别的预测分数，如果差异大于一定阈值则不产生损失，否则产生损失。
   - 公式：Hinge Loss=max⁡(0,1−�⋅�^)Hinge Loss=max(0,1−*y*⋅*y*^) 其中 �*y* 是真实标签（1 或 -1），�^*y*^ 是模型的预测。

3. **Logistic Loss（Log Loss）**：

   - Logistic Loss 也称为对数损失，通常用于二分类任务中。它基于逻辑回归模型的概率预测，衡量了模型对于样本属于正类别的概率的预测与真实标签的差异。
   - 公式：$L=-ylog(\hat y)-(1-y)log(1-\hat y)$

   交叉熵损失更适用于多分类问题，因为它可以直接衡量模型对于每个类别的概率预测与真实分布之间的差异。Logistic 损失更适用于二分类问题，它与逻辑回归模型的概率预测密切相关，适用于输出为二元值的情况。

   

### 交叉熵的求解过程？N 分类任务;

```python
def cross_entropy(y_true, y_pred):
    """
    y_true: shape[m, N], m个样本，N个类别, one_hot
    y_pred: shape[m, N], m个样本，N个类别, 概率值
    """
    epsilon = 1e-5
    loss = -np.mean(y_true*np.log(y_pred+epsilon))
    return loss
```



### 常见的注意力机制

1. SE模块

```python
class SELayer(nn.Module):
    def __init__(self, channel, reduction=16):
        super(SELayer, self).__init__()
        self.avg_pool = nn.AdaptiveAvgPool2d(1)
        self.fc = nn.Sequential(
            nn.Linear(channel, channel // reduction, bias=False),
            nn.ReLU(inplace=True),
            nn.Linear(channel // reduction, channel, bias=False),
            nn.Sigmoid()
        )
 
    def forward(self, x):
        b, c, _, _ = x.size()
        y = self.avg_pool(x).view(b, c)
        y = self.fc(y).view(b, c, 1, 1)
        return x * y.expand_as(x)
```



![img](https://img-blog.csdnimg.cn/e68deb8b324841d09aaced4ce9cd3a8e.png)

2. CA模块

```python
import torch
from torch import nn
class CA_Block(nn.Module):
    def __init__(self, channel, h, w, reduction=16):
        super(CA_Block, self).__init__()
        self.h = h
        self.w = w
        self.avg_pool_x = nn.AdaptiveAvgPool2d((h, 1))
        self.avg_pool_y = nn.AdaptiveAvgPool2d((1, w))
        self.conv_1x1 = nn.Conv2d(in_channels=channel, out_channels=channel//reduction, kernel_size=1, stride=1, bias=False)
        self.relu = nn.ReLU()
        self.bn = nn.BatchNorm2d(channel//reduction)
        self.F_h = nn.Conv2d(in_channels=channel//reduction, out_channels=channel, kernel_size=1, stride=1, bias=False)
        self.F_w = nn.Conv2d(in_channels=channel//reduction, out_channels=channel, kernel_size=1, stride=1, bias=False)
        self.sigmoid_h = nn.Sigmoid()
        self.sigmoid_w = nn.Sigmoid()
    def forward(self, x):
        x_h = self.avg_pool_x(x).permute(0, 1, 3, 2)
        x_w = self.avg_pool_y(x)
        x_cat_conv_relu = self.relu(self.conv_1x1(torch.cat((x_h, x_w), 3)))
        x_cat_conv_split_h, x_cat_conv_split_w = x_cat_conv_relu.split([self.h, self.w], 3)
        s_h = self.sigmoid_h(self.F_h(x_cat_conv_split_h.permute(0, 1, 3, 2)))
        s_w = self.sigmoid_w(self.F_w(x_cat_conv_split_w))
        out = x * s_h.expand_as(x) * s_w.expand_as(x)
        return out
```

![img](https://img-blog.csdnimg.cn/232b3dc1ed854fcfb97607d2f71ad7cd.png)

3. 自注意力机制：用于处理序列数据，如文本、语音等。它能够根据序列中各个元素之间的相互关系动态地计算每个元素的权重。

```python
import torch
import torch.nn as nn
import torch.nn.functional as F

class MultiHeadAttention(nn.Module):
    def __init__(self, embed_dim, num_heads):
        super(MultiHeadAttention, self).__init__()
        assert embed_dim % num_heads == 0, "Embedding dimension must be divisible by the number of heads."
        self.embed_dim = embed_dim
        self.num_heads = num_heads
        self.head_dim = embed_dim // num_heads

        # 初始化线性变换矩阵
        self.W_q = nn.Linear(embed_dim, embed_dim, bias=False)
        self.W_k = nn.Linear(embed_dim, embed_dim, bias=False)
        self.W_v = nn.Linear(embed_dim, embed_dim, bias=False)

        # 输出线性变换矩阵
        self.W_o = nn.Linear(embed_dim, embed_dim)

    def forward(self, query, key, value, mask=None):
        batch_size = query.shape[0]

        # 线性变换
        Q = self.W_q(query)  # 形状: (batch_size, seq_len, embed_dim)
        K = self.W_k(key)    # 形状: (batch_size, seq_len, embed_dim)
        V = self.W_v(value)  # 形状: (batch_size, seq_len, embed_dim)

        # 重塑为多头
        Q = Q.view(batch_size, -1, self.num_heads, self.head_dim).permute(0, 2, 1, 3)  # 形状: (batch_size, num_heads, seq_len, head_dim)
        K = K.view(batch_size, -1, self.num_heads, self.head_dim).permute(0, 2, 1, 3)  # 形状: (batch_size, num_heads, seq_len, head_dim)
        V = V.view(batch_size, -1, self.num_heads, self.head_dim).permute(0, 2, 1, 3)  # 形状: (batch_size, num_heads, seq_len, head_dim)

        # 计算注意力分数
        scores = torch.matmul(Q, K.transpose(-2, -1)) / torch.sqrt(torch.tensor(self.head_dim, dtype=torch.float32))
        if mask is not None:
            scores.masked_fill_(mask == 0, float('-inf'))

        # 使用 softmax 激活函数计算注意力权重
        attn_probs = F.softmax(scores, dim=-1)  # 形状: (batch_size, num_heads, seq_len, seq_len)

        # 使用注意力权重对值进行加权求和
        attn_output = torch.matmul(attn_probs, V)  # 形状: (batch_size, num_heads, seq_len, head_dim)

        # 拼接多头并投影回原始嵌入维度
        attn_output = attn_output.permute(0, 2, 1, 3).contiguous().view(batch_size, -1, self.embed_dim)  # 形状: (batch_size, seq_len, embed_dim)

        # 使用线性变换得到最终的注意力输出
        attn_output = self.W_o(attn_output)  # 形状: (batch_size, seq_len, embed_dim)

        return attn_output
```



3. 交叉注意力机制：用于处理具有不同输入的模型，如图像与文本之间的关系。它允许模型在处理不同输入时动态地计算各个输入之间的关联性，从而更好地整合不同输入的信息。



### 为什么Transformer要使用LayerNorm

归一化的公式：
$$
Norm(x)=\gamma\frac{x-\mu}{\sqrt{\sigma^2+\epsilon}}+\beta
$$
其中，$\gamma$和$\beta$是可学习的缩放和平移参数。

BatchNorm中：
$$
\mu=\frac{1}{m}\sum_{i=1}^mx^i
$$

$$
\sigma^2=\frac{1}{m}\sum_{i=1}^m(x^i-\mu)^2
$$

其中，m是批量样本的大小，$x^i$是第$i$个样本的输出；把一个batch中同一个通道的所有特征是为一个分布（有几个通道就有几个分布），并将其标准化，这意味着：不同图片的的同一通道的相对关系是保留的，即不同图片的同一通达的特征是可以比较的；同一图片的不同通道的特征则是失去了可比性；

LayerNorm中：
$$
\mu=\frac{1}{n}\sum_{i=1}^nx_i
$$

$$
\sigma^2=\frac{1}{n}\sum_{i=1}^n(x_i-\mu)^2
$$

其中，$n$ 是特征的维度，$x_i$是第$i$ 个特征的值。把一个句子的所有词向量视为一个分布（有几个句子就有几个分布），并将其归一化。这意味着：同一个句子中的词向量的相对大小是保留的；不同句子的词向量失去了可比性。



任何norm的意义都是为了让使用norm的网络的输入的数据分布变得更好，也就是转换为标准正态分布，数值进入敏感度区间，以减缓梯度消失，从而更容易训练。当然，这也意味着舍弃了除此维度之外其他维度的其他信息。首先要明确，如果在一个维度内进行normalization，那么在这个维度内，相对大小有意义的，是可以比较的；但是在normalization后的不同的维度之间，相对大小这是没有意义的。

相比于稳定前向输入分布，反向传播时mean和variance计算引入的梯度更有用，可以稳定反向传播时loss对输入的梯度。LN特别适合处理变长数据，因为是对channel维度做操作(这里指NLP中的hidden维度)，和句子长度和batch大小无关。

自己的理解：不同句子之间的词向量不需要有可比较的关系；



### 为什么self-attention可以堆叠多层，有什么作用

Self-attention（自注意力）能够捕捉输入序列中的长距离依赖关系，通过堆叠多层self-attention，模型可以学习序列中更深层次的模式和依赖关系。多层self-attention就像神经网络中的多个隐藏层一样，使模型能够学习和表示更复杂的函数。



### Transformer与CNN的优缺点

**Transformer 的优点：**

1. **适用于序列数据：** Transformer 主要应用于处理序列数据，如自然语言处理（NLP）任务中的文本序列。由于其自注意力机制的引入，Transformer 能够捕获序列中任意两个位置之间的依赖关系，从而更好地建模长距离依赖。
2. **并行计算：** Transformer 的自注意力机制允许每个位置的输入直接和所有其他位置的输入进行交互，使得模型在处理长序列时具有较好的并行性，能够高效地利用硬件资源。
3. **位置编码：** Transformer 使用位置编码来表示输入序列中的位置信息，这使得模型能够区分不同位置的词或符号，有助于模型理解序列的顺序信息。
4. **可解释性：** Transformer 模型的自注意力机制使得模型在生成预测时能够关注输入序列中的不同部分，从而具有一定的可解释性，可以分析模型在做出决策时的注意力分布情况。

**Transformer 的缺点：**

1. **计算复杂度高：** Transformer 模型通常需要较大的参数量，且在处理长序列时，由于自注意力机制的全连接特性，计算复杂度较高，可能导致训练和推理速度较慢。
2. **数据量要求高：** Transformer 模型通常需要大量的数据来进行训练，特别是在没有预训练模型的情况下，需要更多的数据来学习到有效的表示。

**CNN 的优点：**

1. **适用于图像数据：** CNN 主要应用于处理图像数据，具有良好的特征提取能力，能够捕获图像中的局部特征和层次结构。
2. **参数共享和稀疏连接：** CNN 中的卷积层具有参数共享和稀疏连接的特性，这使得模型具有较少的参数量和更高的参数效率，适合处理大规模图像数据。
3. **平移不变性：** CNN 中的卷积操作具有平移不变性，即对图像的平移操作具有一定的鲁棒性，能够在一定程度上保持对图像中相同特征的识别能力。

**CNN 的缺点：**

1. **局限于固定大小的输入：** CNN 在处理图像时通常需要固定大小的输入，因此对于尺寸不一致的图像数据需要进行预处理或者裁剪，可能会丢失一部分信息。
2. **不适用于序列数据：** CNN 不适用于处理序列数据，因为其卷积操作是基于固定大小的局部感受野进行的，无法捕获序列中不同位置之间的依赖关系。

### Transformer 中的位置编码在哪实现的？是固定的，还是可以学习？

位置编码通常被加到输入嵌入之后，以将位置信息与词嵌入结合起来，从而使模型能够区分不同位置的词。

一种常用的位置编码方法是使用正弦和余弦函数的组合：
$$
PE(pos, 2i)=sin(pos/10000^{2i/d_{model}})
$$

$$
PE(pos,2i+1)=cos(pos/10000^{2i/d_{model}})
$$



### 多头注意力机制和单头相比有什么优势

多头注意力机制可以同时关注输入的不同部分，并在不同的表示空间中学习到不同的表示。这使得模型能够更好地捕捉输入序列的局部和全局信息，提高了表示的丰富性和多样性；多头的本质是多个独立的attention计算，作为一个集成的作用，防止过拟合，因为每个头都可以学习到不同的关注点，从而减少了对单个注意力头的过度依赖；



### 多头注意力机制的计算复杂度

矩阵乘法的复杂度：假设A是$n×m$的矩阵，$B$是$m×p$的矩阵，那么$A×B$的复杂度为`O(mnp)`

1. 对于$n×d$和$d×n$的矩阵$Q$,$K^T$，矩阵相乘的复杂度为$O(n^2d)$​
2. softmax函数：$O(n^2)$
3. 加权平均：矩阵相乘，$O(n^2d)$

所以自注意力机制的计算复杂度为$O(n^2d)$

多头注意力机制的计算复杂度为$O(mn^2h)=O(n^2d)$



### Transformer中的head为什么要降维？

就是希望每个注意力头，只关注最终输出序列中一个子空间，互相**独立**。其核心思想在于，抽取到更加丰富的**特征信息**。在**不增加时间复杂度**的情况下，同时，借鉴**[CNN](https://www.zhihu.com/search?q=CNN&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra={"sourceType"%3A"answer"%2C"sourceId"%3A1718672303})多核**的思想，在**更低的维度**，在**多个独立的[特征空间](https://www.zhihu.com/search?q=特征空间&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra={"sourceType"%3A"answer"%2C"sourceId"%3A1718672303})**，**更容易**学习到更丰富的[特征信息](https://www.zhihu.com/search?q=特征信息&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra={"sourceType"%3A"answer"%2C"sourceId"%3A1718672303})。



### ViT 结构

但是当训练数据集不够大的时候，ViT的表现通常比同等大小的ResNets要差一些，因为Transformer和CNN相比缺少归纳偏置（inductive bias），即一种先验知识，提前做好的假设。CNN具有两种归纳偏置，一种是局部性（locality/two-dimensional neighborhood structure），即图片上相邻的区域具有相似的特征；一种是平移不变形（translation equivariance）。

ViT将输入图片分为多个patch（16x16），再将每个patch投影为固定长度的向量送入Transformer。对图片分类，因此在输入序列中加入一个特殊的token，该token对应的输出即为最后的类别预测。

**patch embedding：**输入图片大小为224x224，将图片分为固定大小的patch，patch大小为16x16，则每张图像会生成224x224/16x16=196个patch，即输入序列长度为**196**，每个patch维度16x16x3=**768**，线性投射层的维度为768xN (N=768)，因此输入通过线性投射层之后的维度依然为196x768，即一共有196个token，每个token的维度是768。还需要加上一个特殊字符cls，因此最终的维度是**197x768**。到目前为止，已经通过patch embedding将一个视觉问题转化为了一个seq2seq问题。

**positional embedding：**位置编码可以理解为一张表，表一共有N行，N的大小和输入序列长度相同，每一行代表一个向量，向量的维度和输入序列embedding的维度相同（768）。

1-D 位置编码：例如3x3共9个patch，patch编码为1到9

2-D 位置编码：patch编码为11,12,13,21,22,23,31,32,33，即同时考虑X和Y轴的信息，每个轴的编码维度是D/2

**图片大小：**当输入图片分辨率发生变化，输入序列的长度也发生变化，虽然ViT可以处理任意长度的序列，但是预训练好的位置编码无法再使用。一种做法是使用插值算法，扩大位置编码表。但是如果序列长度变化过大，插值操作会损失模型性能，这是ViT在微调时的一种局限性

![img](https://pic4.zhimg.com/80/v2-5afd38bd10b279f3a572b13cda399233_720w.webp)



### DETR中匈牙利匹配算法的具体流程

DETR不需要NMS，采用的是集合预测损失。在DETR中固定会输出N个预测框，如何将预测框与GT对应起来？

二分匹配问题：找到一组边集合，这组边集合没有公共的顶点。

例子：N个工人，M个任务，每个工人对应不同任务的价钱不同，如何以最小的代价完成任务。

![image-20240319161646416](assets/image-20240319161646416.png)

第一步，构建匹配代价$L_{match}$​​​来进行匈牙利算法的最优分配，其中考虑了Ground truth与预测框之间的类别预测以及距离的代价；第二步，对前一步中匹配的所有配对的匈牙利损失，这个损失函数为类预测的负对数似然和边界框损失的线性组合。



### 实例的匹配问题

```python
    def pair_coordinates(setA, setB, radius):
        """Use the Munkres or Kuhn-Munkres algorithm to find the most optimal
        unique pairing (largest possible match) when pairing points in set B
        against points in set A, using distance as cost function.
        Args:
            setA, setB: np.array (float32) of size Nx2 contains the of XY coordinate
                        of N different points
            radius: valid area around a point in setA to consider
                    a given coordinate in setB a candidate for match
        Return:
            pairing: pairing is an array of indices
            where point at index pairing[0] in set A paired with point
            in set B at index pairing[1]
            unparedA, unpairedB: remaining poitn in set A and set B unpaired
        """
        # * Euclidean distance as the cost matrix
        pair_distance = scipy.spatial.distance.cdist(setA, setB, metric='euclidean')

        # * Munkres pairing with scipy library
        # the algorithm return (row indices, matched column indices)
        # if there is multiple same cost in a row, index of first occurence
        # is return, thus the unique pairing is ensured
        indicesA, paired_indicesB = linear_sum_assignment(pair_distance)

        # extract the paired cost and remove instances
        # outside of designated radius
        pair_cost = pair_distance[indicesA, paired_indicesB]

        pairedA = indicesA[pair_cost <= radius]
        pairedB = paired_indicesB[pair_cost <= radius]

        pairing = np.concatenate([pairedA[:, None], pairedB[:, None]], axis=-1)
        unpairedA = np.delete(np.arange(setA.shape[0]), pairedA)
        unpairedB = np.delete(np.arange(setB.shape[0]), pairedB)
        return pairing, unpairedA, unpairedB
```





### TensorRT优化流程

1. **网络定义和训练：** 首先，你需要定义一个深度学习模型并进行训练，通常使用常见的深度学习框架如TensorFlow、PyTorch或Caffe等。这个模型可以是用于分类、目标检测、语义分割等各种任务的模型。
2. **模型转换：** 接下来，你需要将训练好的模型转换为TensorRT的可优化格式。TensorRT支持从常见的深度学习框架（如TensorFlow、PyTorch等）导入模型，并将其转换为TensorRT的网络结构格式。这个过程通常被称为模型优化。
3. **网络优化：** 一旦模型被转换为TensorRT的格式，TensorRT可以对网络进行各种优化，以提高推理性能。这些优化包括结构优化、精度混合、内存优化、层融合、图剪枝等。
4. **引擎构建：** 在网络优化完成后，你需要使用TensorRT API构建推理引擎。推理引擎是TensorRT中的一个重要概念，它是一个针对特定硬件配置和推理需求进行了优化的二进制文件。构建引擎的过程会将优化后的网络结构映射到特定的硬件上，以实现最佳的推理性能。
5. **推理过程：** 最后，你可以使用TensorRT推理引擎对输入数据进行推理。推理引擎会利用之前优化的网络结构和硬件特性，高效地执行推理操作，并生成模型对输入数据的预测结果。



### 介绍YOLO v3~YOLO v8



### 为什么业内yolov5用的比较多而不是yolov8



### focal loss如何计算

Focal Loss（焦点损失）是一种用于解决类别不平衡问题的损失函数。Focal Loss在计算损失时对易分样本的权重进行了降低，这样可以减少易分样本对训练的影响，从而更加关注那些难分的样本，提高模型在类别不平衡情况下的性能。
$$
FL(p_t)=-\alpha(1-p_t)^\gamma log(p_t)
$$




### Iou loss 比 smooth l1 loss好在哪

可以反映预测框与真实框的接近程度；具有很好的**尺度不变性**，也就是尺度不敏感。

Smooth L1 loss 求出4个点（x，y，w，h）Loss后，再相加得到最终的Loss，这种做法的假设是4个点事相互独立的，但实际上是有一定相关性的。

在目标检测时，实际是用IOU来作为评价目标框的指标，而上述Loss函数与IOU是不等价的，**多个目标框可能有相同大小的Smooth L1 Loss，但是他们的IOU可能差异很大**。



### 计算IOU

```python
def calculate_iou(box_1, box_2):
    """
    calculate iou
    :param box_1: (x0, y0, x1, y1)
    :param box_2: (x0, y0, x1, y1)
    :return: value of iou
    """
    # calculate area of each box
    area_1 = (box_1[2] - box_1[0]) * (box_1[3] - box_1[1])
    area_2 = (box_2[2] - box_2[0]) * (box_1[3] - box_1[1])
 
    # find the edge of intersect box
    top = max(box_1[0], box_2[0])
    left = max(box_1[1], box_2[1])
    bottom = min(box_1[3], box_2[3])
    right = min(box_1[2], box_2[2])
 
    # if there is an intersect area
    if left >= right or top >= bottom:
        return 0
 
    # calculate the intersect area
    area_intersection = (right - left) * (bottom - top)
 
    # calculate the union area
    area_union = area_1 + area_2 - area_intersection
 
    iou = float(area_intersection) / area_union
 
    return iou
```



### 谈一下 faster rcnn 和 yolo

two-stage,首先产生候选区域，然后对位置精修后进行候选区域分类。two-stage检测算法识别错误率低，漏识别率也较低，但速度较慢，不能满足实时检测场景，比如视频目标检测中。

one-stage检测算法不需要产生候选区域阶段，直接产生物体的类别概率和位置坐标值，经过单次检测即可直接得到最终的检测结果，因此有着更快的检测速度，但是一般识别精度和准确度上比two-stage的算法要差一些。

单阶段的正负样本太不均衡，两阶段的会划分正负样本均匀化。



### 目标检测中，单双阶段分别目的是什么？

单阶段检测器旨在通过单个神经网络模型直接检测图像中的目标，而不需要额外的区域提议生成步骤。因此，它们的主要目的是简化检测流程，提高检测速度。

双阶段检测器的主要目的是提高检测的准确性，即在保持较高准确率的同时，可能牺牲一些检测速度。它们通常包含两个主要阶段：生成候选区域和对候选区域进行分类与回归。



### RPN（Region Proposal Network）网络

![在这里插入图片描述](https://img-blog.csdnimg.cn/20201124183306197.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2l0bGlseWVy,size_16,color_FFFFFF,t_70#pic_center)

1. 生成Anchor： 特征图中的每一个点都是一个anchor，每个anchor中有9中不同大小和宽高比的预设anchor box；
2. FPN利用一个3*3的卷积核得到一个256维度的向量，分别通过全连接层降维成2×9与4×9维，通过softmax进行二分类已经边框回归来使得anchor box更接近ground truth；



### Faster RCNN 中检测的网络如何适应不同的框的大小？

1. 采用了一种称为金字塔特征金字塔（Feature Pyramid Network，FPN）的技术。FPN 是一种多尺度特征图提取方法，可以在不同层级上生成具有不同分辨率的特征图，使模型能够在多个尺度下进行检测。
2. 预设了3中不同大小宽高的anchor box；



### 谈谈DETR, DETR 中的 query 怎么来的？



### 为什么UNet在医学图像上表现这么好

1. 医学图像语义较为简单、结构较为固定。所以高级语义信息和低级特征都显得很重要(UNet的skip connection和[U型结构](https://www.zhihu.com/search?q=U型结构&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra={"sourceType"%3A"answer"%2C"sourceId"%3A586501606})就派上了用场)。
2. .数据量少。医学影像的数据获取相对难一些，很多比赛只提供不到100例数据。所以我们设计的模型不宜多大，参数过多，很容易导致[过拟合](https://www.zhihu.com/search?q=过拟合&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra={"sourceType"%3A"answer"%2C"sourceId"%3A586501606})。



### 密集行人检测的遮挡问题怎么解决

1. 损失函数Repulsion loss：
   $$
   L_{Rep}=L_{Attr}+\alpha*L_{RepGT}+\beta*L_{RepBox}
   $$
   其中 $$L_{Attr} $$ 是吸引项，需要预测框靠近其指定目标；$L_RepGT$ 和 $L_RepBox$ 是排斥项，分别需要预测框远离周遭其他的 groundtruth 物体和其他指定目标不同的预测框。



### 自动驾驶检测模型如何针对corner case优化

Corner cases(CC)是指不经常出现或一些极端的场景数据，也是一种长尾问题的表现形式。

**置信度(Confidence score)：**通过神经网络估计不确定coner case的置信的，确定是否是异常情况。

**重建(Reconstructive):**对异常对象进行重建，或者仿真模拟得出异常对象数据，加入模型训练。

**生成coner case（Generative):**对异常对象和数据进行扩充，利用GAN等技术生成扩充的coner case案例。

**特征抽取coner case(Feature Extraction):**利用聚类或者svm等分类算法，对coner case案例进行快速的定位。

**预测补充coner case(Prediction):**利用前后帧之间运动物体不会凭空消失或突变等，进行异常情况的校正回归。



### 介绍NMS及其变体

1. Soft-NMS：通过降低重叠边界框的置信度来保留更多信息，将其得分进行惩罚衰减



### NMS的缺点及其改进工作

```python
# 很多检测框都是检测同一个目标，但最终每个目标只需要一个检测框，NMS选择那个得分最高的检测框
import numpy as np

def calculate_iou(box1, box2):
    """
    计算两个边界框的交并比（IoU）
    """
    # 提取边界框的坐标
    x1_tl, y1_tl, x1_br, y1_br = box1
    x2_tl, y2_tl, x2_br, y2_br = box2

    # 计算交集的坐标
    x_intersection = max(0, min(x1_br, x2_br) - max(x1_tl, x2_tl))
    y_intersection = max(0, min(y1_br, y2_br) - max(y1_tl, y2_tl))
    intersection = x_intersection * y_intersection

    # 计算并集的面积
    area_box1 = (x1_br - x1_tl) * (y1_br - y1_tl)
    area_box2 = (x2_br - x2_tl) * (y2_br - y2_tl)
    union = area_box1 + area_box2 - intersection

    # 计算交并比
    iou = intersection / union
    return iou

def non_max_suppression(boxes, scores, threshold):
    """
    非极大值抑制算法
    """
    # 按照置信度排序
    sorted_indices = np.argsort(scores)[::-1]
    selected_indices = []

    while len(sorted_indices) > 0:
        # 选择置信度最高的边界框
        best_index = sorted_indices[0]
        selected_indices.append(best_index)

        # 计算当前边界框与其余边界框的IoU
        ious = [calculate_iou(boxes[best_index], boxes[idx]) for idx in sorted_indices[1:]]

        # 移除与当前边界框IoU大于阈值的边界框
        remove_indices = np.where(np.array(ious) > threshold)[0] + 1
        sorted_indices = np.delete(sorted_indices, remove_indices)

    return selected_indices
```

##### 缺点：

1. 参数敏感：NMS的性能受到参数的影响，不同的数据集和场景可能需要不同的参数设置。
2. 计算开销： 在大规模数据集上运行NMS可能会消耗大量的计算资源
3. 抑制不完全：NMS可能会错误地移除真实目标边界框，特别是当目标之间有部分遮挡或重叠时。
4. 处理不规则目标困难：对于不规则形状或大小不一的目标，NMS的效果可能不理想。
5. 将相邻检测框的分数均强制归零

改进方法：

1. Soft-NMS：通过降低重叠边界框的置信度来保留更多信息，将其得分进行惩罚衰减



### 多卡的BN如何实现同步

1. **跨GPU批量归一化（Cross-GPU Batch Normalization）：** 在这种方法中，每个GPU都有自己的批量归一化层。在每个mini-batch的处理过程中，每个GPU分别计算出均值和方差，并进行归一化处理。然后，通过在所有GPU上汇总并取平均，来计算整个mini-batch的全局均值和方差。最后，所有GPU上的数据都使用这些全局均值和方差进行归一化。这种方法在训练时可以实现较好的批量归一化效果，但需要在推理时仔细处理，因为此时可能不再有多个GPU可用。
2. **同步批量归一化（Synchronized Batch Normalization）：** 这种方法在训练时和推理时都可以有效地实现批量归一化。在同步批量归一化中，所有GPU上的数据都收集到一个单一的批量上。然后，通过在所有GPU上计算均值和方差，并进行同步操作来得到全局均值和方差。最后，所有GPU上的数据都使用这些全局均值和方差进行归一化。这种方法保证了所有GPU上的数据都使用相同的均值和方差进行归一化，从而确保了批量归一化的一致性。



### 如何检测到未知目标

**开放集识别：**模型应该拒绝未知类，而不是以高置信度将其辨认为已知类。

1. OpenMax:
2. 模型集成：
3. 置信度估计：



### pytorch里面两种浮点类型怎么样混合计算的

利用单精度浮点数（float32）和半精度浮点数（float16）的混合来提高训练速度和减少内存占用。

在计算过程中，PyTorch会自动将梯度和参数转换为合适的精度。通常情况下，梯度计算会使用float32进行累积和计算，而参数更新则可以使用float16来提高计算速度。

由于float16的动态范围较小，可能会导致梯度消失或爆炸的问题。为了解决这个问题，混合精度通常会对损失进行缩放，使其适应float16的范围。这可以通过调整损失值的放大因子来实现。



### 为什么MIL的梯度传递不到CNN

1. **高分辨率与海量补丁**：WSIs具有极高的分辨率，通常包含成千上万甚至几十万个补丁（patch）。每个补丁在特征提取阶段需要经过多层卷积网络（如ResNet50）处理，生成中间特征图（activation maps）。这些特征图在反向传播时是梯度计算所必需的，用于更新网络权重。
2. **内存限制与存储需求**：为了进行梯度更新，所有补丁在前向传播过程中产生的中间特征图必须同时存储在GPU内存中。然而，每个补丁的中间特征图占用的内存相当大（如文中给出的ResNet50处理一个256x256补丁需约98.25MB），对于成千上万的补丁，总内存需求会迅速飙升至数百GB，远超出普通计算平台的GPU内存容量。
3. **内存瓶颈与训练障碍**：由于上述巨大的内存需求，直接端到端地优化整个MIL模型（包括特征提取器和MIL聚合器）会导致严重的内存溢出，无法在实际硬件条件下完成反向传播和梯度更新。因此，梯度无法有效地从MIL聚合器回传到特征提取器，阻碍了特征提取器的学习与优化。



### 计算图的概念

计算图由节点（Nodes）和边（Edges）组成，其中节点表示变量、操作或函数，边表示这些节点之间的依赖关系或数据流动。计算图可以是有向无环图（DAG），其中节点之间的连接方向表示计算的顺序。



### 自动微分

自动微分的基本思想是利用计算图和链式法则来实现导数的计算。计算图表示了计算过程中各个变量之间的依赖关系，通过追踪计算图中的路径和对应的微分操作，可以高效地计算出最终结果相对于输入变量的导数。



### 反向传播梯度推导

对于方程$y=wx+b$，损失函数为$L=\frac{1}{2}(y-y_{gt})^2$

那么$\frac{\partial L}{partial w}=\frac{\partial L}{\partial y}\frac{\partial y}{partial w}=(y-y_{gt})x$,$\frac{\partial L}{\partial b}=\frac{\partial L}{\partial y}\frac{\partial y}{\partial b}=y-y_{gt}$



### BCL中的贝叶斯体现在哪里

在这篇文章中，贝叶斯定理体现在对整个协作学习框架的建模过程中，尤其是在目标全片图像（Whole-Slide Image, WSI）分类器与辅助补丁分类器协作学习的统一贝叶斯概率框架中。具体而言，贝叶斯定理的应用体现在以下几个关键点：

1. **最大似然估计（Maximum Likelihood Estimation, MLE）问题的设定**：从贝叶斯概率视角出发，文章将协作学习任务表述为一个最大似然估计问题，即寻找模型参数 \($ \theta $) 以最大化训练数据集中所有样本 \( $(X_i, Y_i)$ \) 的联合概率。公式(3)表达了这一目标，其中 \($ P(Y_i|X_i;\theta)$ \) 是在给定 \($ X_i$ \) 时观察到 \( $Y_i$ \) 的条件概率。通过最大化这个概率的对数乘积，模型试图找到最能解释数据生成过程的参数集。

2. **引入隐变量**：为了便于后续使用EM算法进行优化，引入了隐变量 \($ Z_i = (z_{i1}, ..., z_{iN_i})$ \)，其中 \($ z_{in}$ \) 表示 \( $X_i$ \) 中第 \( n \) 个补丁 \($ x_{in}$ \) 的类别标签。这一步体现了贝叶斯统计中利用潜在变量来描述复杂数据生成机制的特点。

3. **联合概率分布**：定义了联合概率 \( $P(Y_i, Z_i|X_i;\theta)$ \)，它反映了给定 \($ X_i$ \) 时，WSI标签 \($ Y_i$ \) 和所有补丁标签 \( $Z_i$ \) 同时出现的概率。通过引入隐变量 \($Z_i$ \)，模型可以处理WSI分类中涉及的多个实例（补丁）之间的关系，而不仅仅依赖于单个实例的标签。

4. **使用EM算法求解**：EM算法（Expectation-Maximization）是一种迭代优化方法，专门用于含有隐变量的模型参数估计。在这种情况下，它被用来解决由贝叶斯概率框架定义的最大似然估计问题。EM算法通过交替执行E步（期望步）和M步（最大化步），逐步逼近模型参数的最大似然估计值。

- **E步**：计算在当前模型参数下，给定观测数据和WSI标签时，所有可能的补丁标签配置 \( Z_i \) 的概率 \( $P(Z_i|X_i,Y_i;\theta_t)$ \)。E步中，利用贝叶斯规则将后验概率分解为似然和先验的乘积，这里通过对每个补丁进行伪标签分配来实现。

- **M步**：基于E步得到的隐变量分布，更新模型参数以最大化包含所有样本的总目标函数。在M步中，模型参数的更新通过最大化 \( $\sum_{i=1}^{|D|} J_i(\theta,\theta_t)$ \) 来实现，其中 \( $J_i$ \) 是根据E步计算出的每个样本的目标函数。这里的参数更新遵循了贝叶斯框架下极大后验概率估计（Maximum A Posteriori, MAP）的精神，虽然没有显式写出后验概率，但通过对似然函数的极大化，间接实现了参数的MAP估计。

综上所述，文章中的贝叶斯定理体现在构建了一个基于贝叶斯概率的协作学习框架，该框架通过引入隐变量描述WSI分类问题中补丁级别的标签信息，并利用EM算法来解决含有隐变量的最大似然估计问题。EM算法正是在这种贝叶斯背景下的一种有效优化工具，它利用贝叶斯定理将复杂的联合优化问题分解成两个相对简单的步骤（E步计算期望，M步最大化目标函数），从而有效地估计模型参数。这种结合贝叶斯概率建模与EM算法的方法旨在解决WSI分类中的内存瓶颈问题，同时确保特征编码器与MIL聚合器能够协同学习，提高分类性能。





# GAN

### GAN 是用来干什么的，怎么用的，介绍一下它的数学原理？

用于生成以假乱真的数据，如图像、音频或文本。它由两个神经网络组成：生成器和判别器。生成器试图生成与真实数据相似的样本，而判别器则试图区分生成的样本和真实的样本。

GAN 的数学原理基于博弈论和梯度下降优化。生成器和判别器通过最小化损失函数进行训练。生成器的损失函数包括两部分：一部分是生成的样本被判别为真实样本的概率的负对数似然，另一部分是生成的样本与真实样本之间的相似性度量（如欧氏距离或交叉熵）。判别器的损失函数包括两部分：一部分是将生成的样本误判为真实样本的概率的负对数似然，另一部分是将真实样本误判为生成的样本的概率的负对数似然。



### JS散度

JS（Jensen-Shannon）散度是一种用于度量两个概率分布之间的相似性的方法。是KL（Kullback-Leibler）散度的对称形式。
$$
JSD(P||D)=\frac{1}{2}KL(P||M)+\frac{1}{2}KL(Q||M),M是P和Q的平均分布
$$
KL散度用于度量一个概率分布相对于另一个概率分布的不确定性。它的计算公式如下：
$$
KL(P||Q)=\sum_xP(x)log\frac{P(x)}{Q(x)}
$$
**JS散度的缺点：**如果两个分布 P,Q 离得很远，完全没有重叠的时候，那么KL散度值是没有意义的，此时JS散度值是一个常数，梯度为0。



### GAN 为什么不好收敛？

1. GAN 的训练过程涉及到两个网络（生成器和判别器）之间的对抗，这种对抗性可以导致训练过程的不稳定。
2. 生成器和判别器之间的博弈过程相当复杂，因为两者的目标是互相优化，但是没有一个明确的最优解。
3. 模式崩溃： 当生成器找到了一个成功愚弄判别器的策略时，它可能会生成少数几种高度相似的样本，而忽视其他潜在的数据分布。这导致生成的样本缺乏多样性，而且可能无法涵盖真实数据分布的所有模式。
4. 梯度消失和梯度爆炸： 在训练过程中，生成器和判别器的梯度计算可能会出现梯度消失或梯度爆炸问题，这可能导致参数更新不稳定，进而影响收敛性。
5. 超参数选择： GAN 的训练涉及许多超参数，如学习率、网络结构、损失函数权重等。不当的超参数选择可能导致训练过程难以收敛。



### 为什么 GAN 中的优化器不常用 SGD？

1. SGD 在 GAN 中可能导致训练过程不稳定
2. SGD 在深度神经网络中可能会引起梯度消失或梯度爆炸问题
3. GAN 的损失函数是一个非常复杂的非凸函数，存在许多局部最小值和鞍点。SGD 在寻找全局最小值时可能会受到困扰。



### GAN的损失函数是什么？

$$
loss_D=-log(D(x))-log(1-D(G(z)))
$$

$$
loss_G=-log(D(G(z)))
$$



### 训练GAN的技巧

1. 选择合适的损失函数可以影响训练的结果。传统的 GAN 使用最小最大博弈的损失函数，但更稳定的变体如 WGAN，在某些情况下可以更好地处理模式崩溃和梯度消失等问题。
2. 使用正则化技术如权重剪枝、批量归一化等，可以帮助稳定训练过程。
3. 确保生成器和判别器的能力相当。过强的生成器可能会导致模式崩溃，而过强的判别器可能会阻碍生成器的学习。
4. 确保生成器和判别器的能力相当。过强的生成器可能会导致模式崩溃，而过强的判别器可能会阻碍生成器的学习。
5. 在每个训练迭代中，可以选择更新判别器的次数超过生成器，以确保判别器能够跟上生成器的更新速度。



### WGAN为什么能处理梯度消失和梯度爆炸

在标准的GAN中，由于使用了生成器和判别器之间的交叉熵损失函数，**当生成器的输出与真实数据的分布差异较大时，梯度可能会消失或爆炸，导致训练不稳定**。

Wasserstein距离在数学上对几乎所有概率分布都是有意义的，并且**具有更好的连续性和凸性质**，因此更容易优化。
$$
Loss_G=-E(D(G(z)))
$$

$$
Loss_D=E(D(x))-E(D(G(z)))
$$

此外，WGAN还引入了一些其他技术，如**权重剪裁（weight clipping）或梯度惩罚（gradient penalty）**，进一步提高了稳定性和收敛速度。



### Pix2pix 和 cycleGan 的区别？

Pix2Pix旨在学习图像之间的一对一映射，即给定输入图像，生成对应的输出图像。

CycleGAN旨在学习两个域之间的映射，而不需要成对的训练数据。CycleGAN采用了循环一致性损失，允许模型在没有成对训练数据的情况下学习域之间的映射。



### LSGANs

LSGANs（Least Squares Generative Adversarial Networks）是一种生成对抗网络（GAN）的变种，旨在改善原始GAN中的训练稳定性和生成图像的质量。LSGANs的主要特点是**使用最小二乘损失函数**来代替原始GAN中的二元交叉熵损失函数。

二元交叉熵损失函数在训练过程中可能会导致**模式崩溃（mode collapse）或梯度消失**的问题，尤其是在训练初期。
$$
L_G=\frac{1}{2}\mathbb{E}_{x~p_{data}(x)}[(D(G(z))-1)^2]
$$

$$
L_D=\frac{1}{2}\mathbb{E}_{x~p_{data}(x)}[(D(x)-1)^2]+\frac{1}{2}\mathbb{E}_{z~p_z(z)}[D(G(z))^2]
$$

LSGANs使用了最小二乘损失函数，这使得生成器和判别器在训练过程中对真实和生成数据的处理**更加平滑**。通过使用最小二乘损失函数，LSGANs可以提高训练的稳定性，减少模式崩溃和梯度消失的问题，同时生成更加逼真的图像。



### 模式崩溃问题

指的是生成器倾向于生成相似或重复的样本，而忽略了数据分布中的多样性。

1. **判别器过于强大**：如果判别器能够准确地区分生成的样本和真实的样本，那么生成器可能会找到一种简单的生成方式，以欺骗判别器，而忽略了数据分布中的其他模式。
2. **训练不稳定**：GAN的训练过程本身就很不稳定，当生成器和判别器的更新速度不平衡或损失函数设计不合理时，容易导致模式崩溃。
3. **数据分布不均匀**：如果数据集中某些模式的出现频率比其他模式高得多，生成器可能会倾向于生成这些常见的模式，而忽略了其他模式。

避免方法：

1. **增加数据多样性**：确保训练数据集包含各种不同的模式和样本，以便生成器能够学习到整个数据分布的多样性。
2. **使用正则化技术**：通过添加正则化项或限制生成器的容量，可以防止生成器学习到过度简化的模型。
3. **改进损失函数**：设计更合适的损失函数，例如使用Wasserstein距离或Least Squares损失，可以改善训练的稳定性，减少模式崩溃的发生。
4. **监督训练**：在训练过程中监督生成器的学习过程，确保生成器生成的样本涵盖了整个数据分布的多样性，而不仅仅是局部的模式。



### DCGAN

DCGAN（Deep Convolutional Generative Adversarial Networks）是生成对抗网络（GAN）的一个改进版本，旨在通过引入深度卷积神经网络来提高生成器和判别器的性能和稳定性。



### 生成对抗网络能否用于其他任务

1. **语音合成和转换**：GAN可以用于生成逼真的语音样本，或者用于语音转换任务，例如从一种语音风格转换为另一种语音风格，或者实现说话人转换。
2. **文本生成**：GAN可以用于生成逼真的文本数据，例如生成自然语言描述的图像、生成对话或故事等。
3. **数据增强**：GAN可以用于生成合成数据，以增加训练数据的多样性和丰富性，从而提高深度学习模型的性能。



### 什么是生成对抗网络的生成器的输入噪声（Latent Noise）？为什么要引入噪声？

生成对抗网络（GAN）的生成器的输入噪声（Latent Noise）是一个随机向量或随机张量，通常从某种潜在空间中随机采样而得。生成器将这个噪声作为输入，并试图将其转换为逼真的数据样本，例如图像、音频或文本。

1. **增加数据多样性**：通过在生成器的输入中引入随机噪声，可以促使生成器生成**多样化**的数据样本。这样可以**防止生成器过度拟合**训练数据，并使其生成更加多样化和逼真的样本。

2. **提高模型的鲁棒性**：噪声可以增加模型的鲁棒性，使其更能够处理来自不同分布或具有不同特征的数据。这有助于生成器更好地泛化到新的、未见过的数据样本。
3. **控制生成样本的多样性**：通过调整输入噪声的分布或参数，可以控制生成器生成样本的多样性程度。这可以用于生成样本的插值、插图、样式变换等应用。



### GAN如何处理多模态数据，例如文本到图像的生成

将文本描述转换为文本嵌入（text embedding）或语义向量（semantic vector），然后将这些向量作为生成器的输入之一。在训练过程中，同时使用文本描述和对应的图像作为输入数据。生成器的输入可以是随机噪声和文本描述的组合，而判别器则同时判断生成的图像和真实图像的逼真程度。

cGAN是一种生成对抗网络的变种，它在生成器和判别器中都引入了条件信息，通常是将文本描述作为生成器和判别器的条件输入。这样生成器可以根据给定的文本描述生成相应的图像，而判别器可以根据文本描述来判断生成的图像的逼真程度。



# VAE



# Diffusion



















































